{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4139f23",
   "metadata": {},
   "source": [
    "# Lenght of stay prediction\n",
    "\n",
    "@References : Soenksen, L.R., Ma, Y., Zeng, C. et al. Integrated multimodal artificial intelligence framework for healthcare applications. npj Digit. Med. 5, 149 (2022). https://doi.org/10.1038/s41746-022-00689-4\n",
    "\n",
    "In this notebook, the task is to predict lenght of stay using the CSV embeddings file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9e247e",
   "metadata": {},
   "source": [
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321d5924",
   "metadata": {},
   "source": [
    "The goal of this part of the study is to build models to predict whether or not a patient will be discharged without expiration during the next 48 h as a binary classification problem: discharged alive ≤48 h (1) or otherwise (0). In case of patient death, the class label is set to 0. Each sample in this predictive task corresponds to a single patient-admission EHR time point where an X-ray image was obtained (N = 45,050).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59600fd4",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d0990d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from pandas import read_csv\n",
    "\n",
    "from src.data import constants\n",
    "from src.data.dataset import HAIMDataset\n",
    "from src.data.sampling import Sampler\n",
    "from src.evaluation.evaluating import Evaluator\n",
    "from src.evaluation.tuning import SklearnTuner\n",
    "from src.utils.metric_scores import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645a1fe8",
   "metadata": {},
   "source": [
    "#### Read data from local source\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a948c18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_csv(FILE_DF, nrows=df = read_csv(constants.FILE_DF, nrows=constants.N_DATA))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a95053",
   "metadata": {},
   "source": [
    "#### Create a custom dataset for the HAIM experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ff78fb",
   "metadata": {},
   "source": [
    "Build the target column for the task at hand, set the dataset specificities:  the ``haim_id`` as a ``global_id``, use all sources for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "239db8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HAIMDataset(df,  \n",
    "                      constants.ALL_PREDICTORS, \n",
    "                      constants.ALL_MODALITIES, \n",
    "                      constants.LOS, \n",
    "                      constants.IMG_ID, \n",
    "                      constants.GLOBAL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9f8354",
   "metadata": {},
   "source": [
    "#### Create the sampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe30725",
   "metadata": {},
   "source": [
    "Sample the data using a 5 folds cross-validation method based on unique ``haim_id`` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8cc844e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 5/5 [00:00<00:00, 2788.77it/s]\n"
     ]
    }
   ],
   "source": [
    "sampler = Sampler(dataset, constants.GLOBAL_ID, 5)\n",
    "_, masks = sampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abdd3c8",
   "metadata": {},
   "source": [
    "#### Select the evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f935bbb8",
   "metadata": {},
   "source": [
    "Initilialize a list containing the evaluation metrics to report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ceec6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of the list containing the evaluation metrics\n",
    "evaluation_metrics = [BinaryAccuracy(), \n",
    "                      BinaryBalancedAccuracy(),\n",
    "                      BinaryBalancedAccuracy(Reduction.GEO_MEAN),\n",
    "                      Sensitivity(), \n",
    "                      Specificity(), \n",
    "                      AUC(), \n",
    "                      BrierScore(),\n",
    "                      BinaryCrossEntropy()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114f173f",
   "metadata": {},
   "source": [
    "#### Set hyper-parameters and fixed parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d6cb174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid oh hyper-parameters for the tuning\n",
    "grid_hps = {'max_depth': [5, 6, 7, 8],\n",
    "            'n_estimators': [200, 300],\n",
    "            'learning_rate': [0.3, 0.1, 0.05],\n",
    "            }\n",
    "\n",
    "# Save the fixed parameters of the model\n",
    "fixed_params = {'seed': 42,\n",
    "                'eval_metric': 'logloss',\n",
    "                'verbosity': 0\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fd10ab",
   "metadata": {},
   "source": [
    "### Model training and predictions using an XGBClassifier model with GridSearchCV and Hyperparameters optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04a4c63",
   "metadata": {},
   "source": [
    "The goal of this section of the notebook is to compute the following metrics:\n",
    "\n",
    "``ACCURACY_SCORE, BALANCED_ACCURACY_SCORE, SENSITIVITY, SPECIFICITY, AUC, BRIER SCORE, BINARY CROSS-ENTROPY``\n",
    "\n",
    "\n",
    "The\n",
    "hyperparameter combinations of individual XGBoost models were\n",
    "selected within each training loop using a ``fivefold cross-validated\n",
    "grid search`` on the training set (80%). This XGBoost ``tuning process``\n",
    "selected the ``maximum depth of the trees (5–8)``, the number of\n",
    "``estimators (200 or 300)``, and the ``learning rate (0.05, 0.1, 0.3)``\n",
    "according to the parameter value combination leading to the\n",
    "highest observed AUROC within the training loop \n",
    "\n",
    "\n",
    "As mentioned previously, all XGBoost models were trained ``five times with five different data splits`` to repeat the\n",
    "experiments and compute average metrics \n",
    "\n",
    "\n",
    "```Refer to page 8 of study``` : https://doi.org/10.1038/s41746-022-00689-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726c2332",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = Evaluator(dataset=dataset,\n",
    "                       masks=masks,\n",
    "                       metrics=evaluation_metrics,\n",
    "                       model=XGBClassifier,\n",
    "                       tuner=SklearnTuner,\n",
    "                       tuning_metric=AUC(),\n",
    "                       hps=grid_hps,\n",
    "                       n_tuning_splits=5,\n",
    "                       fixed_params=fixed_params,\n",
    "                       filepath=constants.EXPERIMENT_PATH,\n",
    "                       weight='scale_pos_weight',\n",
    "                       evaluation_name='48h los'\n",
    "                       )\n",
    "evaluation.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6787a8cc",
   "metadata": {},
   "source": [
    "#### Comparison with the paper results:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b517ec5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>BalancedAcc</th>\n",
       "      <th>GeoBalancedAcc</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>AUC</th>\n",
       "      <th>BrierScore</th>\n",
       "      <th>BCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_metrics</th>\n",
       "      <td>1.0 +- 0.0</td>\n",
       "      <td>1.0 +- 0.0</td>\n",
       "      <td>1.0 +- 0.0</td>\n",
       "      <td>1.0 +- 0.0</td>\n",
       "      <td>1.0 +- 0.0</td>\n",
       "      <td>1.0 +- 0.0</td>\n",
       "      <td>0.0 +- 0.0</td>\n",
       "      <td>0.0009 +- 0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_metrics</th>\n",
       "      <td>0.924 +- 0.0038</td>\n",
       "      <td>0.5532 +- 0.006</td>\n",
       "      <td>0.3266 +- 0.0182</td>\n",
       "      <td>0.1071 +- 0.0118</td>\n",
       "      <td>0.9993 +- 0.0003</td>\n",
       "      <td>0.9323 +- 0.0115</td>\n",
       "      <td>0.0461 +- 0.0033</td>\n",
       "      <td>0.2077 +- 0.0293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAIM</th>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>0.939</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NON_HAIM</th>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>0.919</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Accuracy      BalancedAcc    GeoBalancedAcc  \\\n",
       "train_metrics       1.0 +- 0.0       1.0 +- 0.0        1.0 +- 0.0   \n",
       "test_metrics   0.924 +- 0.0038  0.5532 +- 0.006  0.3266 +- 0.0182   \n",
       "HAIM                        --               --                --   \n",
       "NON_HAIM                    --               --                --   \n",
       "\n",
       "                    Sensitivity       Specificity               AUC  \\\n",
       "train_metrics        1.0 +- 0.0        1.0 +- 0.0        1.0 +- 0.0   \n",
       "test_metrics   0.1071 +- 0.0118  0.9993 +- 0.0003  0.9323 +- 0.0115   \n",
       "HAIM                         --                --             0.939   \n",
       "NON_HAIM                     --                --             0.919   \n",
       "\n",
       "                     BrierScore               BCE  \n",
       "train_metrics        0.0 +- 0.0  0.0009 +- 0.0004  \n",
       "test_metrics   0.0461 +- 0.0033  0.2077 +- 0.0293  \n",
       "HAIM                         --                --  \n",
       "NON_HAIM                     --                --  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Evaluator.visualize_results('experiments/48h los', constants.LOS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HAIM",
   "language": "python",
   "name": "haim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
